{
   "pba":{
      "status":"ACTIVE",
      "serviceInfo":{
         "id":"",
         "description":"Apache Kafka based service for Beam.",
         "serviceType":"IO",
         "technology":"kafka-beam",
         "version":"0.10.2.1"
      },
      "extensionPoints":[
         {
            "technology":"kafka-beam",
            "description":"The Kafka data source allows the application to read streams of data from topics in the Kafka cluster.",
            "uri":{
               "protocol":"kafka://",
               "address":"<Topic Name>",
			   "help":"Kafka url in the format kafka://<topic name>?format=json/csv/avro/gpb",
               "args":[
                  {
                     "key":"format",
                     "value":[
                        "JSON",
                        "Avro",
                        "CSV",
                        "Google Protocol Buffer"
                     ],
                     "type":"array"
                  }
               ]
            },
            "attributes":[
               {
                  "key":"bootstrap.servers",
                  "value":"localhost:9092",
                  "regex":".*",
                  "isReadOnly":false,
                  "help":"A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. The client will make use of all servers irrespective of which servers are specified here for bootstrapping—this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form host1:port1,host2:port2,...",
                  "isRequired":true,
                  "type":"string"
               },
               {
                  "key":"group.id",
                  "value":"<group_1>",
                  "isReadOnly":false,
                  "help":"A unique string that identifies the consumer group this consumer belongs to. This property is required if the consumer uses either the group management functionality by using subscribe(topic) or the Kafka-based offset management strategy.",
                  "isRequired":true,
                  "type":"string"
               },
               {
                  "key":"kafka.topics",
                  "value":"",
                  "isReadOnly":false,
                  "help":"Available Kafka Topics.",
                  "isRequired":true,
                  "type":"string"
               },
               {
                  "key":"max.poll.records",
                  "value":"",
                  "isReadOnly":false,
                  "help":"The maximum polling records frequencey value.",
                  "isRequired":true,
                  "type":"string"
               },
               {
                  "key":"key.deserializer",
                  "value":"org.apache.kafka.common.serialization.StringDeserializer",
                  "isReadOnly":false,
                  "help":"Deserializer class for key that implements the Deserializer interface.",
                  "isRequired":true,
                  "type":"string"
               },
               {
                  "key":"value.deserializer",
                  "value":"org.apache.kafka.common.serialization.StringDeserializer",
                  "isReadOnly":false,
                  "help":"Deserializer class for value that implements the Deserializer interface.",
                  "isRequired":true,
                  "type":"string"
               }
            ]
         }
      ],
      "integrationPoints":[
         {
            "technology":"kafka-beam",
            "description":"The Kafka data sink allows the application to write streams of data to topics in the Kafka cluster.",
            "uri":{
               "protocol":"kafka://",
               "address":"<Topic Name>",
			   "help":"Kafka url in the format kafka://<topic name>?format=json/csv/avro/gpb",
               "args":[
                  {
                     "key":"format",
                     "value":[
                        "JSON",
                        "Avro",
                        "CSV",
                        "Google Protocol Buffer"
                     ],
                     "type":"array"
                  }
               ]
            },
            "attributes":[
               {
                  "key":"bootstrap.servers",
                  "value":"localhost:9092",
                  "isReadOnly":false,
                  "help":"A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. The client will make use of all servers irrespective of which servers are specified here for bootstrapping—this list only impacts the initial hosts used to discover the full set of servers. This list should be in the form host1:port1,host2:port2,...",
                  "isRequired":true,
                  "type":"string"
               },
               {
                  "key":"key.serializer",
                  "value":"org.apache.kafka.common.serialization.StringSerializer",
                  "isReadOnly":false,
                  "help":"Serializer class for key that implements the Serializer interface.",
                  "isRequired":true,
                  "type":"string"
               },
               {
                  "key":"value.serializer",
                  "value":"org.apache.kafka.common.serialization.StringSerializer",
                  "isReadOnly":false,
                  "help":"Serializer class for value that implements the Serializer interface.",
                  "isRequired":true,
                  "type":"string"
               },
               {
                "key":"max.poll.records",
                "value":"",
                "isReadOnly":false,
                "help":"The maximum polling records frequencey value.",
                "isRequired":true,
                "type":"string"
             },
             {
                "key":"publish.value.only",
                "value":false,
                "isReadOnly":false,
                "help":"If this flag enabled in the flow xml property for the kafka output, it will publishe only values.",
                "isRequired":true,
                "type":"boolean"
             }
            ]
         }
      ],
      "buildInfo":{
         "container":{
            "docker":{
               "name":"kafka:0.10.2.1",
               "repoBaseUrl":"armdocker.rnd.ericsson.se",
               "repoPath":"aia_releases",
               "imagePath":"kafka:0.10.2.1",
               "network":"HOST",
               "portList":[

               ],
               "mountPaths":[

               ],
               "mountName":[

               ],
               "forcePullImage":true,
               "privileged":true
            }
         },
         "dependencies":[
            "service:background:zookeeper:3.4.10"
         ]
      },
      "deploymentInfo":{
         "servicePorts":[

         ],
         "maturity":0,
         "stagingStatus":true,
         "inProduction":true,
         "deploymentScope":"private|public",
         "noOfInstances":"1",
         "noOfCpuPerInstance":"1",
         "memorySize":"<InGB>",
         "envArgs":[

         ],
         "appArgs":[
            {
               "key":"mainClass",
               "value":"<main-classofSparkapp>"
            },
            {
               "key":"deployMode",
               "value":"<client/cluster>"
            },
            {
               "key":"masterUrl",
               "value":"<sparkmaster-ip:port>"
            },
            {
               "key":"bpsJar",
               "value":"hdfs://<pathonhdfs>"
            },
            {
               "key":"flowPath",
               "value":"hdfs://<pathonhdfs>"
            },
            {
               "key":"jobArguments",
               "value":"<otherarguments>"
            }
         ],
         "attributes":[

         ]
      }
   }
}